{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4741f8",
   "metadata": {},
   "source": [
    "#                         Navdeep Sureka 19BCE2679 DA 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff31077",
   "metadata": {},
   "source": [
    "### 1) Demonstrate possible missing value analysis approaches using any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14cb52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64727e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6395212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read the description for the dataset \n",
    "\n",
    "# with open('../DATA/Ames_Housing_Feature_Description.txt','r') as f: \n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c85790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DATA/Ames_housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('PID',axis=1) #PID is the unique row number and will not be used.. so we are dropping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support function to plot all the missing values with the percentage \n",
    "def percent_missing(df):\n",
    "    percent_nan = 100* df.isnull().sum() / len(df)\n",
    "    percent_nan = percent_nan[percent_nan>0].sort_values()\n",
    "    return percent_nan\n",
    "percent_nan = percent_missing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=percent_nan.index,y=percent_nan)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can clearly see that some column have less than 1% of the data as missing ->\n",
    "#Drop the row or fill the missing value\n",
    "\n",
    "\n",
    "# And lot of column got most of the data missing -> \n",
    "#Drop the feature column all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the row with missing values\n",
    "df = df.dropna(axis=0,subset= ['Electrical','Garage Cars','Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the missing data based on the domian knowledge and dec given with the dataset\n",
    "df[\"Mas Vnr Type\"] = df[\"Mas Vnr Type\"].fillna(\"None\")\n",
    "df[\"Mas Vnr Area\"] = df[\"Mas Vnr Area\"].fillna(0)\n",
    "gar_str_cols = ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond']\n",
    "df[gar_str_cols] = df[gar_str_cols].fillna('None')\n",
    "df['Garage Yr Blt'] = df['Garage Yr Blt'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "sns.barplot(x=percent_nan.index,y=percent_nan)\n",
    "plt.xticks(rotation=90);\n",
    "# New updated missing values after add and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d722cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Pool QC','Misc Feature','Alley','Fence','Fireplace Qu','Neighborhood','Lot Frontage'],axis=1)\n",
    "#Dropping the entire feature column as most of the datapoint is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f30257",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nan = percent_missing(df)\n",
    "percent_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally all the missing value is either filled or deleted \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3fcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98993222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------END of exp 1 --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6649b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3eadc99",
   "metadata": {},
   "source": [
    "### 2. Write a program to demonstrate the working of the simple linear regression. Use an appropriate data set for building the best line fit and compute the Mean absolute error, mean squared error, root mean square, and R square value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c420348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    "Advertising data contain 200 rows of data with 4 columns (3 feature and 1 sale value)\n",
    "Feature includes:\n",
    "TV ad-spend amount unit\n",
    "Radio ad-spend amount unit Newspaper ad-spend amount unit\n",
    "And a sales column with sale amount unit \n",
    "\"\"\"\n",
    "\n",
    "df=pd.read_csv(\"DATA/Advertising.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6738077",
   "metadata": {},
   "outputs": [],
   "source": [
    " #defining the X-features and ylabel\n",
    "X=df.drop(\"sales\",axis=1)\n",
    "y=df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #importing scikit-learn train-test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f66789",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "# print(len(X_train))\n",
    "# print(len(X_test))\n",
    "# print(len(X))\n",
    "# X_train+X_test should be equal to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing linear regression model algo from sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our own model\n",
    "my_model=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting train data to our model\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89814bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction=my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance evaluation #MAE and RMSE\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "\n",
    "MAE=mean_absolute_error(y_test,test_prediction)\n",
    "MSE=mean_squared_error(y_test,test_prediction)\n",
    "RMSE=np.sqrt(MSE)\n",
    "print(\"MAE~ \",MAE)\n",
    "print(\"MSE*~ \",MSE)\n",
    "print(\"RMSE~ \",RMSE)\n",
    "print(\"R-square value~ \",r2_score(y_test,test_prediction))\n",
    "\n",
    "#high RMSE compared to MAE suggest that there are some outliers with high deviation\n",
    "#error is +/-\n",
    "error_percentage = MAE*100/df[\"sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f1e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "test_res = y_test - test_prediction\n",
    "# Create a figure and axis to plot on\n",
    "fig, ax = plt.subplots(figsize=(6,8),dpi=100)\n",
    "# probplot returns the raw values if needed\n",
    "# we just want to see the plot, so we assign these values to _\n",
    "_ = sp.stats.probplot(test_res,plot=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------End of section 2 --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e8029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b19dbd5e",
   "metadata": {},
   "source": [
    "### 3. Implement a logistic regression algorithm and test the algorithm using any data set of your choice from the UCI repository. The output should include Accuracy, Error rate, Precision, and recall rate along with the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a36b33",
   "metadata": {},
   "source": [
    "Data description\n",
    "This database contains 14 physical attributes based on physical testing of a patient. Blood samples are taken and the patient also conducts a brief exercise test. The \"goal\" field refers to the presence of heart disease in the patient. It is integer (0 for no presence, 1 for presence). In general, to confirm 100% if a patient has heart disease can be quite an invasive process, so if we can create a model that accurately predicts the likelihood of heart disease, we can help avoid expensive and invasive procedures.\n",
    "\n",
    "Original Source: https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cc607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Classification Model that can predict whether or not a person has presence of heart disease based on physical features of that person (age,sex, cholesterol, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3422e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234068cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output (Target) contain only 2 possible output 0 or 1 . It is a binary classification dataset.\n",
    "sns.countplot(x='target',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf33482",
   "metadata": {},
   "source": [
    "##### The output is evenly distributed and we can use accuracy as the performance mea sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007cadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# We will be using stdscaller for scalling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "# 10% of data for test and 90% for training with 101 as random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12228b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    " scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "# We will be using CV (inbuild crossvalidation logistic reg model to train out data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ecbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.fit(scaled_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace97d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix\n",
    "plot_confusion_matrix(log_model,scaled_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy_score: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision_score: \",precision_score(y_test,y_pred))\n",
    "print(\"Recall_score: \",recall_score(y_test,y_pred))\n",
    "print(\"Error-rate: \",1-accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------End of section 3-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91bd2761",
   "metadata": {},
   "source": [
    "### 4. Building a Classifier Using Decision Tree to predict the COVID-19 Severity. Print out the Accuracy, classification error, sensitivity, specificity, precision, and Confusion Matrix of Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdd257",
   "metadata": {},
   "source": [
    "##### Link: https://www.kaggle.com/datasets/iamhungundji/covid19-symptoms-checker?select=Cleaned-Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA/Cleaned-Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_columns = df.filter(like='Severity_').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity_None'].replace({1:'None',0:'No'},inplace =True)\n",
    "df['Severity_Mild'].replace({1:'Mild',0:'No'},inplace =True)\n",
    "df['Severity_Moderate'].replace({1:'Moderate',0:'No'},inplace =True)\n",
    "df['Severity_Severe'].replace({1:'Severe',0:'No'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5681029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition']=df[severity_columns].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing(list1):\n",
    "    list1 = set(list1) \n",
    "    list1.discard(\"No\")\n",
    "    a = ''.join(list1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition'] = df['Condition'].apply(removing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fa29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_columns = df.filter(like='Age_').columns\n",
    "gender_columns = df.filter(like='Gender_').columns\n",
    "contact_columns = df.filter(like='Contact_').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_risk_age = df.groupby(['Severity_None'])[age_columns].sum()\n",
    "No_risk_gender = df.groupby(['Severity_None'])[gender_columns].sum()\n",
    "No_risk_contact = df.groupby(['Severity_None'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baab473",
   "metadata": {},
   "outputs": [],
   "source": [
    "Low_risk_age = df.groupby(['Severity_Mild'])[age_columns].sum()\n",
    "Low_risk_gender = df.groupby(['Severity_Mild'])[gender_columns].sum()\n",
    "Low_risk_contact = df.groupby(['Severity_Mild'])[contact_columns].sum()\n",
    "\n",
    "Moderate_risk_age = df.groupby(['Severity_Moderate'])[age_columns].sum()\n",
    "Moderate_risk_gender = df.groupby(['Severity_Moderate'])[gender_columns].sum()\n",
    "Moderate_risk_contact = df.groupby(['Severity_Moderate'])[contact_columns].sum()\n",
    "\n",
    "Severe_risk_age = df.groupby(['Severity_Severe'])[age_columns].sum()\n",
    "Severe_risk_gender = df.groupby(['Severity_Severe'])[gender_columns].sum()\n",
    "Severe_risk_contact = df.groupby(['Severity_Severe'])[contact_columns].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Country\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ac55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(severity_columns,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ca500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symptoms_Score'] = df.iloc[:,:5].sum(axis=1) + df.iloc[:,6:10].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['Condition'] = le.fit_transform(df['Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['Condition'],axis=1)\n",
    "y= df['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d125e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f7b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13736f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix, Accuracy, sensitivity and specificity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test,base_pred)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"Recall : \",recall_score(y_test,base_pred,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import plot_tree\n",
    "# plt.figure(figsize=(12,8))\n",
    "# plot_tree(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3775f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9a0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06035ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ab14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
